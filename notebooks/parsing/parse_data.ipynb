{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parse_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn2e7pGb8gD1"
      },
      "source": [
        "# imports and data mountage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAozqLPDqzga",
        "outputId": "0f821bc2-73e4-43b6-a4e2-b3a89fd6f09c"
      },
      "source": [
        "!pip install --upgrade pandas\n",
        "!pip install --upgrade pyarrow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (6.0.1)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pyarrow) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UgR5xB1_8jqi",
        "outputId": "244155d2-1402-4756-a153-afd4dcfbd1f3"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import pyarrow.dataset as ds\n",
        "import numpy as np\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "\n",
        "pd.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.3.4'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bBTxrA084tt",
        "outputId": "0fb65588-77ad-4cac-f89c-de821444778d"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aywwvNir_VLC"
      },
      "source": [
        "logging.basicConfig(level=logging.DEBUG, filename='/content/drive/MyDrive/parsed_quotes2/quotes.log')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24ZrQO5G8vSa"
      },
      "source": [
        "# read files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAzwG03k83sv"
      },
      "source": [
        "path_to_attr = '/content/drive/MyDrive/Project datasets/speaker_attributes.parquet'\n",
        "path_to_quotbank_desc = '/content/drive/MyDrive/Project datasets/wikidata_labels_descriptions_quotebank.csv.bz2'\n",
        "path_to_quotbank = '/content/drive/MyDrive/Quotebank/quotes-2020.json.bz2' "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o9Vk1GZNzrq"
      },
      "source": [
        "paths_to_quotbank = [f'/content/drive/MyDrive/Quotebank/quotes-20{i}.json.bz2' for i in range(15, 21)]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uY1p8kvCtmz"
      },
      "source": [
        "columns = ['date_of_birth', 'nationality', 'gender', 'ethnic_group', 'occupation', 'party', 'academic_degree', 'id', 'candidacy', 'religion']\n",
        "attr = pd.read_parquet(path_to_attr, columns=columns)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTxH8j0bk3eu"
      },
      "source": [
        "descriptions = pd.read_csv(path_to_quotbank_desc, compression='bz2', index_col='QID') "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5hwN-ETtVEU"
      },
      "source": [
        "### Exceptions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyzZ-iWbtYHy"
      },
      "source": [
        "exeptions = ['Q3268166', 'Q11815360', 'Q12014399', 'Q16287483', 'Q20432251',\n",
        "             'Q21550646', 'Q13365117', 'Q13424794', 'Q1248362', 'Q3186984',\n",
        "             'Q6859927', 'Q15145782', 'Q15991263', 'Q99753484', 'Q12455619',\n",
        "             'Q5568256', 'Q6363085', 'Q11819457', 'Q12334852', 'Q15145783']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "634MnsW5FzFs"
      },
      "source": [
        "# process data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rN0AsuNl3TY"
      },
      "source": [
        "## Profile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90PdZAUSDrAA"
      },
      "source": [
        "def parse_in_chunks(chunk_size, path_to_save, path_to_save_exceptions, descriptions, exeptions, path_to_quotbank):\n",
        "  quotebank_reader = pd.read_json(path_to_quotbank, lines=True, compression='bz2', chunksize=chunk_size)\n",
        "  columns = ['nationality', 'gender', 'ethnic_group', 'occupation', 'party', 'academic_degree', 'candidacy', 'religion'] \n",
        "  path = path_to_save \n",
        "\n",
        "  for i, quote in tqdm(enumerate(quotebank_reader)):\n",
        "    #multiple people in one quote\n",
        "    quote = quote.explode('qids')\n",
        "\n",
        "    #marge with atributes\n",
        "    quote = quote.merge(attr, how='left', left_on='qids', right_on='id', indicator=True)\n",
        "\n",
        "    #get not in description file quotes \n",
        "    not_in_desc_quotes_mask = quote.applymap(lambda x:  np.isin(x,exeptions).any() if isinstance(x,np.ndarray) else x in exeptions).any(axis=1)\n",
        "    not_in_desc_quotes = quote[not_in_desc_quotes_mask.values]\n",
        "\n",
        "    #get in description file quotes by negation\n",
        "    quote = quote[~not_in_desc_quotes_mask.values]\n",
        "\n",
        "    #decript values\n",
        "    try:\n",
        "      quote[columns] = quote[columns].applymap(lambda x: descriptions.loc[x]['Label'].values[0], na_action='ignore')\n",
        "    except:\n",
        "      logging.exception(f\"on chunk {i} after {i*chunk_size}:\")\n",
        "      print(f\"error {i}\")\n",
        "      continue\n",
        "\n",
        "    #unify NaN to None\n",
        "    quote = quote.where(pd.notnull(quote), None)\n",
        "    not_in_desc_quotes = not_in_desc_quotes.where(pd.notnull(not_in_desc_quotes), None)\n",
        "\n",
        "    #save quotes\n",
        "    table = pa.Table.from_pandas(quote, preserve_index=True)         \n",
        "    pq.write_table(table, path + f\"/{i}\" + \".parquet\")\n",
        "\n",
        "    #save not in description\n",
        "    table = pa.Table.from_pandas(not_in_desc_quotes, preserve_index=True)         \n",
        "    pq.write_table(table, path_to_save_exceptions + f\"/{i}\" + \".parquet\")\n",
        "\n",
        "    if i % 10 == 0:\n",
        "      print((i+1)*chunk_size)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHOsJWccnYYI",
        "outputId": "9ed1d177-8807-4db7-a302-671a2bc3e2ef"
      },
      "source": [
        "%%time\n",
        "for path in paths_to_quotbank:\n",
        "  parse_in_chunks(100000,\"/content/drive/MyDrive/parsed_quotes2/no_exception\", \"/content/drive/MyDrive/parsed_quotes2/exception\", descriptions, exeptions, path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [05:44, 344.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9it [52:54, 355.78s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rcBvus9RXjO"
      },
      "source": [
        "### Check "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSToca4GRZr5"
      },
      "source": [
        "# dataset = ds.dataset(\"/content/drive/MyDrive/quotes/quotes-2020-enhanced10000\", format=\"parquet\")\n",
        "# print(dataset.files)\n",
        "# df = dataset.head(100).to_pandas()\n",
        "# df.info()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RFhASJXKuai"
      },
      "source": [
        "# df.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}